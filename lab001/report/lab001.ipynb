{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python37564bitprevvenvaaf3ad2477cc402fa47ee19ffa39844b",
   "display_name": "Python 3.7.5 64-bit ('prev': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pdb\n",
    "import numpy as np\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Helpful sources: http://mlwak.blogspot.com/2016/06/udacity-assignment-1-not-mnist.html\n",
    "\n",
    "### 1: load data and show some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns data in format { 'folders': {}, 'images': { 'name': file, ...} }\n",
    "def load_images_from_folder(folder):\n",
    "    print(\"Getting images from {}\".format(folder))\n",
    "    result = { 'folders': {}, 'images': {} }\n",
    "    for name in os.listdir(folder):\n",
    "        is_folder = os.path.isdir(os.path.join(folder, name))\n",
    "        if is_folder:\n",
    "            subfolder = os.path.join(folder, name)\n",
    "            result['folders'][name] = load_images_from_folder(subfolder)\n",
    "        else:\n",
    "            img = cv2.imread(os.path.join(folder, name))\n",
    "            if img is not None:\n",
    "                result['images'][name] = img\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(images, sample_size, name):\n",
    "    figure = plt.figure()\n",
    "    figure.suptitle(name)\n",
    "    folders = images['folders']\n",
    "    for folder_name, folder in folders.items():\n",
    "        image_name_samples = random.sample(list(folder['images']), sample_size)\n",
    "        for image_name in image_name_samples:\n",
    "            subplot = figure.add_subplot(\n",
    "                sample_size,\n",
    "                len(folders),\n",
    "                list(folders).index(folder_name) * sample_size + image_name_samples.index(image_name) + 1\n",
    "            )\n",
    "            subplot.imshow(folder['images'][image_name])\n",
    "            subplot.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Getting images from ../notMNIST_large\nGetting images from ../notMNIST_large/B\nGetting images from ../notMNIST_large/F\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-472398ae9d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_sample_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../notMNIST_large'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sample_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dcb0477f020d>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_folder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msubfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'folders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dcb0477f020d>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'folders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_sample_folder = '../notMNIST_small'\n",
    "train_sample_folder = '../notMNIST_large'\n",
    "\n",
    "train_sample = load_images_from_folder(train_sample_folder)\n",
    "test_sample = load_images_from_folder(test_sample_folder)\n",
    "\n",
    "plot_samples(test_sample, 10, 'Test sample')\n",
    "plot_samples(train_sample, 10, 'Train sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2: check if samples are balanced\n",
    "\n",
    "image_size = 28 # Pixel width and height.\n",
    "pixel_depth = 255.0 # Number of levels per pixel.\n",
    "\n",
    "# We'll convert the entire dataset into a 3D array (image index, x, y) of floating point values,\n",
    "# normalized to have approximately zero mean and standard deviation ~0.5\n",
    "# to make training easier down the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_letter(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label.\"\"\"\n",
    "    \"\"\"image_files is an array of all the filenames\"\"\"\n",
    "    image_files = os.listdir(folder)\n",
    "    \"\"\"dataset is an array of length being the total number of images, and each image is 28x28\"\"\"\n",
    "    dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "    print(folder)\n",
    "    num_images = 0\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(folder, image)\n",
    "        try:\n",
    "            \"\"\"this is the normalization step - the formula is [value-(255/2)]/255\"\"\"\n",
    "            image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "            if image_data.shape != (image_size, image_size):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            \"\"\"after the normalization, stick the normalized image\n",
    "               into the dataset array at the nth position\"\"\"\n",
    "            dataset[num_images, :, :] = image_data\n",
    "            num_images = num_images + 1\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                        (num_images, min_num_images))\n",
    "\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle is used for serializing and de-serializing Python object structures,\n",
    "# also called marshalling or flattening.\n",
    "def pickle_dataset(data_folders, min_num_images_per_class):\n",
    "    dataset_names = []\n",
    "    for folder in data_folders:\n",
    "        set_filename = folder + '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename):\n",
    "            # You may override by setting force=True.\n",
    "            print('%s already present - Skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('Pickling %s.' % set_filename)\n",
    "            dataset = load_letter(folder, min_num_images_per_class)\n",
    "            try:\n",
    "                with open(set_filename, 'wb') as f:\n",
    "                    pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':', e)\n",
    "\n",
    "    return dataset_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = pickle_dataset(train_sample['folders'], 45000)\n",
    "test_datasets = pickle_dataset(test_sample['folders'], 1800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_images(datasets):\n",
    "    num = []\n",
    "\n",
    "    for pickle_file in datasets:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            print('Total images in', pickle_file, ':', len(data))\n",
    "            num.append(len(data))\n",
    "\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_check(sizes):\n",
    "    mean_val = mean(sizes)\n",
    "    print('mean of # images :', mean_val)\n",
    "    for i in sizes:\n",
    "        if abs(i - mean_val) > 0.1 * mean_val:\n",
    "            print(\"Too much or less images\")\n",
    "        else:\n",
    "            print(\"Well balanced\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_label(sizes):\n",
    "    labels = np.ndarray(sum(sizes), dtype=np.int32)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for label, size in enumerate(sizes):\n",
    "        start = end\n",
    "        end += size\n",
    "        for j in range(start, end):\n",
    "            labels[j] = label\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_balance(train_labels, test_labels):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    bins = np.arange(train_labels.min(), train_labels.max() + 2)\n",
    "    ax[0].hist(train_labels, bins=bins)\n",
    "    ax[0].set_xticks((bins[:-1] + bins[1:]) / 2, [chr(k) for k in range(ord(\"A\"), ord(\"J\") + 1)])\n",
    "    ax[0].set_title(\"Training data\")\n",
    "\n",
    "    bins = np.arange(test_labels.min(), test_labels.max() + 2)\n",
    "    ax[1].hist(test_labels, bins=bins)\n",
    "    ax[1].set_xticks((bins[:-1] + bins[1:]) / 2, [chr(k) for k in range(ord(\"A\"), ord(\"J\") + 1)])\n",
    "    ax[1].set_title(\"Test data\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = generate_fake_label(num_of_images(test_datasets))\n",
    "train_labels = generate_fake_label(num_of_images(train_datasets))\n",
    "\n",
    "# Checking balance\n",
    "balance_check(num_of_images(test_datasets))\n",
    "balance_check(num_of_images(train_datasets))\n",
    "\n",
    "plot_balance(train_labels=train_labels, test_labels=test_labels)\n"
   ]
  }
 ]
}