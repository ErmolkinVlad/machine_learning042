{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python37564bitprevvenvaaf3ad2477cc402fa47ee19ffa39844b",
   "display_name": "Python 3.7.5 64-bit ('prev': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторная работа №7. Рекуррентные нейронные сети для анализа текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow и tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile\n",
    "from six.moves import cPickle as pickle\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import re\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Задание 1.\n",
    "Загрузите данные. Преобразуйте текстовые файлы во внутренние структуры данных, которые используют индексы вместо слов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка и форматирование данных\n",
    "\n",
    "# used only once\n",
    "# !bash ../data/movie_reviews/preprocess_reviews.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрипт из открытого доступа (https://gist.github.com/aaronkub/09985a47740bda278712e1dd78e482cf) объединяет все негативные рецензии и все позитивные в одни файлы. Он исправлен, чтобы файл был не один."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/movie_reviews/aclImdb/data'\n",
    "\n",
    "def extract_data(filename):\n",
    "    dataset = []\n",
    "    with open(os.path.join(dataset_path, filename)) as f:\n",
    "        for lines in f.readlines():\n",
    "            dataset.append(lines.strip())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_pos_reviews = extract_data('full_pos_train.txt')\n",
    "train_neg_reviews = extract_data('full_neg_train.txt')\n",
    "test_pos_reviews = extract_data('full_pos_test.txt')\n",
    "test_neg_reviews = extract_data('full_neg_test.txt')\n",
    "\n",
    "train_labels = np.concatenate((np.ones(len(train_pos_reviews)), np.zeros(len(train_neg_reviews))), axis=None)\n",
    "test_labels = np.concatenate((np.ones(len(test_pos_reviews)), np.zeros(len(test_neg_reviews))), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train positive lines:  12500\nTrain negative lines:  12500\nTrain labels:  25000\nTest positive lines:  12500\nTest negative lines:  12500\nTest labels:  25000\n"
    }
   ],
   "source": [
    "print('Train positive lines: ', len(train_pos_reviews))\n",
    "print('Train negative lines: ', len(train_neg_reviews))\n",
    "print('Train labels: ', len(train_labels))\n",
    "print('Test positive lines: ', len(test_pos_reviews))\n",
    "print('Test negative lines: ', len(test_neg_reviews))\n",
    "print('Test labels: ', len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
    "\n",
    "Препроцессим данные и делаем их чище (убираем заглавные, знаки препинания и так далее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "# REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "# def preprocess_reviews(reviews):\n",
    "#     reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "#     reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "#     return reviews\n",
    "\n",
    "# train_pos_reviews = preprocess_reviews(train_pos_reviews)\n",
    "# train_neg_reviews = preprocess_reviews(train_neg_reviews)\n",
    "# test_pos_reviews = preprocess_reviews(test_pos_reviews)\n",
    "# test_neg_reviews = preprocess_reviews(test_neg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do\n",
    "# https://stackoverflow.com/questions/42943291/what-does-keras-io-preprocessing-sequence-pad-sequences-do\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train_pos_reviews + train_neg_reviews)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_pos_reviews + train_neg_reviews)\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test_pos_reviews + test_neg_reviews)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train X:  (18750, 2473)\nValid X:  (6250, 2473)\nTest X:  (25000, 2232)\nTrain y:  (18750,)\nValid y:  (6250,)\nTest y:  (25000,)\n"
    }
   ],
   "source": [
    "print('Train X: ', X_train.shape)\n",
    "print('Valid X: ', X_valid.shape)\n",
    "print('Test X: ', X_test.shape)\n",
    "print('Train y: ', y_train.shape)\n",
    "print('Valid y: ', y_valid.shape)\n",
    "print('Test y: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Задание 2.\n",
    "Реализуйте и обучите двунаправленную рекуррентную сеть (LSTM или GRU). Какого качества классификации удалось достичь?\n"
   ]
  }
 ]
}