{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python37564bitprevvenvaaf3ad2477cc402fa47ee19ffa39844b",
   "display_name": "Python 3.7.5 64-bit ('prev': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лабораторная работа №5. Применение сверточных нейронных сетей (бинарная классификация)\n",
    "\n",
    "# TensorFlow и tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile\n",
    "from six.moves import cPickle as pickle\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1.\n",
    "Загрузите данные. Разделите исходный набор данных на обучающую, валидационную и контрольную выборки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful links:\n",
    "# 1) https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "\n",
    "def extract_dataset(name):\n",
    "    zip_path = os.path.join('../data/cats_vs_dogs/', name + '.zip')\n",
    "    if not os.path.exists(os.path.join('../data/cats_vs_dogs/', name)):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"../data/cats_vs_dogs\")\n",
    "\n",
    "extract_dataset('train')\n",
    "\n",
    "def get_file_list_from_dir(folder_path):\n",
    "    all_files = os.listdir(folder_path)\n",
    "    data_files = list(filter(lambda file: file.endswith('.jpg'), all_files))\n",
    "    return data_files\n",
    "\n",
    "\n",
    "filelist = get_file_list_from_dir('../data/cats_vs_dogs/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8725 8775 1276 1225 2499 2500\nFound 17500 images belonging to 2 classes.\nFound 2501 images belonging to 2 classes.\nFound 4999 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "train_folder = '../data/cats_vs_dogs/train'\n",
    "valid_folder = '../data/cats_vs_dogs/valid'\n",
    "test_folder = '../data/cats_vs_dogs/test'\n",
    "\n",
    "train_cats_len = len(os.listdir(os.path.join(train_folder, 'cats') ))\n",
    "train_dogs_len = len(os.listdir(os.path.join(train_folder, 'dogs')))\n",
    "valid_cats_len = len(os.listdir(os.path.join(valid_folder, 'cats') ))\n",
    "valid_dogs_len = len(os.listdir(os.path.join(valid_folder, 'dogs') ))\n",
    "test_cats_len = len(os.listdir(os.path.join(test_folder, 'cats')))\n",
    "test_dogs_len = len(os.listdir(os.path.join(test_folder, 'dogs')))\n",
    "\n",
    "print(train_cats_len, train_dogs_len, valid_cats_len, valid_dogs_len, test_cats_len, test_dogs_len)\n",
    "\n",
    "# using rescale because of empty images issue (https://stackoverflow.com/questions/43292009/keras-and-imagegenerator-outputs-black-images)\n",
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_iterator = data_generator.flow_from_directory(train_folder, class_mode='binary', target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True)\n",
    "valid_iterator = data_generator.flow_from_directory(valid_folder, class_mode='binary', target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True)\n",
    "test_iterator = data_generator.flow_from_directory(test_folder, class_mode='binary', target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_samples(iterator, sample_size, name):\n",
    "    figure, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "    figure.suptitle(name)\n",
    "    axes = axes.flatten()\n",
    "    images = next(iterator)[0][:sample_size]\n",
    "    for img, ax in zip(images, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_samples(train_iterator, 5, 'train')\n",
    "# plot_samples(valid_iterator, 5, 'test')\n",
    "# plot_samples(test_iterator, 5, 'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.\n",
    "Реализуйте глубокую нейронную сеть с как минимум тремя сверточными слоями. Какое качество классификации получено?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "basic_model = Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.Conv2D(256, 3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_19 (Conv2D)           (None, 148, 148, 32)      896       \n_________________________________________________________________\nmax_pooling2d_19 (MaxPooling (None, 74, 74, 32)        0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 74, 74, 32)        0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 72, 72, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_20 (MaxPooling (None, 36, 36, 64)        0         \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 34, 34, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_21 (MaxPooling (None, 17, 17, 128)       0         \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 15, 15, 256)       295168    \n_________________________________________________________________\nmax_pooling2d_22 (MaxPooling (None, 7, 7, 256)         0         \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 7, 7, 256)         0         \n_________________________________________________________________\nflatten_6 (Flatten)          (None, 12544)             0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 256)               3211520   \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 256)               65792     \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 257       \n=================================================================\nTotal params: 3,665,985\nTrainable params: 3,665,985\nNon-trainable params: 0\n_________________________________________________________________\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 150 steps, validate for 50 steps\nEpoch 1/10\n150/150 [==============================] - 191s 1s/step - loss: 0.7295 - accuracy: 0.5240 - val_loss: 0.6827 - val_accuracy: 0.5669\nEpoch 2/10\n150/150 [==============================] - 185s 1s/step - loss: 0.6787 - accuracy: 0.6005 - val_loss: 0.6318 - val_accuracy: 0.6356\nEpoch 3/10\n150/150 [==============================] - 165s 1s/step - loss: 0.6257 - accuracy: 0.6583 - val_loss: 0.5771 - val_accuracy: 0.7013\nEpoch 4/10\n150/150 [==============================] - 171s 1s/step - loss: 0.5780 - accuracy: 0.7008 - val_loss: 0.5793 - val_accuracy: 0.6963\nEpoch 5/10\n150/150 [==============================] - 153s 1s/step - loss: 0.5555 - accuracy: 0.7208 - val_loss: 0.6463 - val_accuracy: 0.6875\nEpoch 6/10\n150/150 [==============================] - 153s 1s/step - loss: 0.5356 - accuracy: 0.7333 - val_loss: 0.5549 - val_accuracy: 0.7337\nEpoch 7/10\n150/150 [==============================] - 173s 1s/step - loss: 0.5205 - accuracy: 0.7490 - val_loss: 0.4904 - val_accuracy: 0.7631\nEpoch 8/10\n150/150 [==============================] - 173s 1s/step - loss: 0.4966 - accuracy: 0.7663 - val_loss: 0.4679 - val_accuracy: 0.7681\nEpoch 9/10\n150/150 [==============================] - 178s 1s/step - loss: 0.4609 - accuracy: 0.7871 - val_loss: 0.4274 - val_accuracy: 0.8000\nEpoch 10/10\n150/150 [==============================] - 172s 1s/step - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.4423 - val_accuracy: 0.8125\n"
    }
   ],
   "source": [
    "basic_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "basic_model.summary()\n",
    "basic_model_history = basic_model.fit_generator(train_iterator, steps_per_epoch=150, epochs=10, validation_data=valid_iterator, validation_steps=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-db9621fbabc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'basic model, basic_model_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-db9621fbabc2>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(histories, key)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         val = plt.plot(history.epoch, history.history['val_' + key],\n\u001b[1;32m      6\u001b[0m                         '--', label=name.title()+' Val')\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def plot_history(histories, key='binary_crossentropy'):\n",
    "    plt.figure(figsize=(16,10))\n",
    "\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch, history.history['val_' + key],\n",
    "                        '--', label=name.title()+' Val')\n",
    "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "                label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "    plt.xlim([0,max(history.epoch)])\n",
    "    plt.show()\n",
    "\n",
    "plot_history([('basic model', basic_model_history)], key='loss')"
   ]
  }
 ]
}